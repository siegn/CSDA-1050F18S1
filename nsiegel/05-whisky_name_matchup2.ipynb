{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Initial-Grouping\" data-toc-modified-id=\"Initial-Grouping-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Initial Grouping</a></span></li><li><span><a href=\"#Find-Keywords-from-Distillery-Names-(And-Other-Important-Terms)\" data-toc-modified-id=\"Find-Keywords-from-Distillery-Names-(And-Other-Important-Terms)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Find Keywords from Distillery Names (And Other Important Terms)</a></span></li><li><span><a href=\"#Extract-Age\" data-toc-modified-id=\"Extract-Age-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Extract Age</a></span></li><li><span><a href=\"#Join-Datasets\" data-toc-modified-id=\"Join-Datasets-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Join Datasets</a></span></li><li><span><a href=\"#Fuzzy-Match\" data-toc-modified-id=\"Fuzzy-Match-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Fuzzy Match</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:17.387842Z",
     "start_time": "2019-07-27T06:02:17.381694Z"
    }
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import sys\n",
    "import pdb\n",
    "from fuzzywuzzy import fuzz\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:17.968135Z",
     "start_time": "2019-07-27T06:02:17.395241Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_parquet('data/db_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:17.987103Z",
     "start_time": "2019-07-27T06:02:17.972262Z"
    }
   },
   "outputs": [],
   "source": [
    "whiskyids = pd.read_parquet('data/whisky_ids.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:18.091934Z",
     "start_time": "2019-07-27T06:02:17.991012Z"
    }
   },
   "outputs": [],
   "source": [
    "lcbo = pd.read_parquet('data/lcbo_whisky.parquet').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:18.100889Z",
     "start_time": "2019-07-27T06:02:18.095697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(664, 45)"
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcbo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:18.412510Z",
     "start_time": "2019-07-27T06:02:18.108316Z"
    }
   },
   "outputs": [],
   "source": [
    "# we actually don't care if a product is in a plastic bottle or not for review purposes, so let's rename them:\n",
    "lcbo['itemname'] = lcbo['itemname'].str.replace('\\(PET\\)','', case=False,regex=True).str.strip()\n",
    "\n",
    "# add count to see how many of the same whisky name we have\n",
    "lcbo['count'] = lcbo.groupby('itemname')['itemnumber'].transform('count')\n",
    "\n",
    "# add a metric to see how far from 750 a bottle is (we want to drop duplicate products of different sizes)\n",
    "lcbo = lcbo.assign(sizedelta = abs(lcbo['productsize'] - 750))\n",
    "\n",
    "# keep only the entry closest to 750 and in case of tie the one with higher price (assuming its the nonpet) :\n",
    "lcbo['rank'] = lcbo.groupby(\"itemname\")['sizedelta'].rank(\"first\", ascending=True)\n",
    "lcbo = lcbo[(lcbo['rank'] == 1)]\n",
    "\n",
    "lcbo = lcbo.drop(['count','sizedelta','rank'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Keywords from Distillery Names (And Other Important Terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:18.423811Z",
     "start_time": "2019-07-27T06:02:18.417322Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_nonwords(sentence):\n",
    "    #return nltk.word_tokenize(sentence)\n",
    "    return [str.lower(word) for word in nltk.word_tokenize(sentence) if not is_word(word)]\n",
    "    \n",
    "def is_word(word):\n",
    "    if wordnet.synsets(word):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def contains_digit(word):\n",
    "    return any(char.isdigit() for char in word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:18.939491Z",
     "start_time": "2019-07-27T06:02:18.426517Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find all words in whisky names that are not english words\n",
    "keywords = lcbo.apply(lambda row: find_nonwords(row['itemname']), axis='columns')\n",
    "\n",
    "# Turn into one list without duplicates\n",
    "keywords = list(keywords.apply(pd.Series).stack().unique())\n",
    "\n",
    "# Filter out purly numeric values\n",
    "keywords = [word for word in keywords if not contains_digit(word)]\n",
    "\n",
    "# Filter out stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "keywords = [word for word in keywords if word not in stopWords]\n",
    "\n",
    "# Filter out punctuation\n",
    "keywords = [word for word in keywords if re.match('^[\\w]+$', word) is not None]\n",
    "\n",
    "# Filter out words that aren't applicable:\n",
    "# These are either: generic descriptors or whisky regions\n",
    "filterlist = ['peated', 'campbeltown', 'speyside', 'yo', 'st', 'oaked', 'wheated', 'ol', 'bbq']\n",
    "\n",
    "keywords = [word for word in keywords if word not in filterlist]\n",
    "\n",
    "# Add back in 1792 because that's the only number we actually want since its a brand, \n",
    "# as well as some other brands that weren't caught\n",
    "\n",
    "# TODO: match bigrams here! Cause some words like Highland screw it up if they are alone\n",
    "\n",
    "\n",
    "                     \n",
    "\n",
    "newwords = [\n",
    "            # brands\n",
    "            '1792', 'gibson', 'signature', \n",
    "            # bigrams need to both be matched:\n",
    "            ('jack','daniels'), ('knob','creek'),('crown','royal'),\n",
    "            'owl', 'jefferson', 'teacher',\n",
    "            'sazerac', 'caribou', 'wiser', 'walker', 'grouse', 'alberta', 'grant', 'bell', \n",
    "            'dewar', 'maker', 'rittenhouse', 'baker', 'revel', 'roses', \n",
    "            'writers', 'writer', 'rogue',  'colonel', 'weller', 'booker', 'mist', 'challenge',\n",
    "            'redbreast',\n",
    "            # qualities\n",
    "            'rare', 'proof',  'organic',\n",
    "            \n",
    "            # region (careful with these)\n",
    "            'canadian', 'canada', 'islay',\n",
    "            \n",
    "            # locations\n",
    "            'virginia','dublin','shetland','trafalgar','caribbean','windsor',  'halifax',\n",
    "            # names\n",
    "            'patrick', 'gretzky', 'cody',\n",
    "    \n",
    "            'irishman', 'rebel',  'compass', '601', 'cork', 'charlotte',\n",
    "            'stalk', 'centennial',   'quiet', 'forester', 'powers', 'temple', 'tucker',\n",
    "            'antiquity', 'feathery',  \n",
    "             'few',  'burnside',   'larceny', 'tango', 'king',\n",
    "            'prescott', 'moray', 'twelve', 'reserve', 'reunion',   'maestri', \n",
    "            'sexton', 'ezra', 'bastille',  'orphan', 'founder',  'wedding', 'shoe',\n",
    "            'caramel', 'moonshine', 'cooper',  'benchmark',\n",
    "            # animals\n",
    "            'bull', 'dog', 'turkey', 'monkey', 'beast', 'fox', 'buffalo','crow',\n",
    "            # colors\n",
    "            'red', 'blue', 'yellow', 'green', 'black', 'brown', 'white', 'gold', 'silver', 'copper',\n",
    "            'golden','blacker', 'golder', 'redder', 'darker',\n",
    "            'dark',\n",
    "            # type\n",
    "            'rye',\n",
    "            'casg',  'horse', 'vintage', 'wood', 'burns', \n",
    "            # barrels\n",
    "            'cognac', 'sherry', 'amarone', 'champagne', #'stout', messes up caskmates\n",
    "            'brandy', 'madeira', 'bordeaux', 'sauternes', 'burgundy',\n",
    "            'sassicaia', 'tokaji',\n",
    "            # barrel count\n",
    "            'triple', 'double', #'single',\n",
    "            'cask', 'new',\n",
    "           \n",
    "            # woods\n",
    "            'cedar', 'heartwood', 'springwood', 'virgin', 'redwood',\n",
    "    \n",
    "            'classic', 'select', 'smws',\n",
    "            'valinch', 'hermitage',\n",
    "            'home',    'traditional',\n",
    "            \n",
    "            # game of thrones\n",
    "            'stark', 'tully',\n",
    "    \n",
    "            'bush', 'art','diamond', \n",
    "            'alpha', \n",
    "            'dawn', 'dusk', 'surf',\n",
    "            'elements',\n",
    "            \n",
    "            'jts',\n",
    "            'growth', 'bere', \n",
    "            \n",
    "            'cuvee', 'infinity',\n",
    "            'octomore', 'resurrection',\n",
    "            'waves', 'river', 'silk' ,'signal', 'winter', 'snow', 'ice', 'fire', \n",
    "            # flavours\n",
    "            'apple', 'vanilla', 'peach', 'honey', 'maple', 'spiced', 'toasted', 'seasoned',\n",
    "            'harvest', 'blenders', \n",
    "            'chairman',\n",
    "            'ellington', 'kirkland',\n",
    "            'mcadam', 'glacier',\n",
    "            'skate', \n",
    "            'pike', 'ileach',\n",
    "            'macaloney', 'cured', 'grain',\n",
    "             'small', 'sour', 'tornado',\n",
    "            'hedonism', 'evolution', \n",
    "            'cross', 'glasgow',\n",
    "            'indian',\n",
    "            'heritage',  \n",
    "            'devil', 'brooks',\n",
    "            'alba', 'major',\n",
    "            'naked', 'eades', 'light',  'entrapment',  'oyo',\n",
    "            'palm', 'lochnagar', 'willett', 'north',\n",
    "            'dissertation', 'last', 'legacy'\n",
    "           ]\n",
    "keywords = keywords + newwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:19:28.338555Z",
     "start_time": "2019-07-27T06:19:28.328479Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_keywords(text, keywords):\n",
    "    # here's how to do it in spark:\n",
    "    #def keyWordMatch(text):\n",
    "    from nltk import ngrams\n",
    "    text = text.lower().replace(\"'\",\"\")\n",
    "    result = []\n",
    "    for k in keywords:\n",
    "        print(k)\n",
    "        if type(k) == tuple:\n",
    "            (word1, word2) = k\n",
    "            k = \" \".join([word1.lower(),word2.lower()])\n",
    "        else:\n",
    "            print(type(k))\n",
    "            k = k.lower()\n",
    "        count = len([gram for gram in ngrams(nltk.word_tokenize(text),len(nltk.word_tokenize(k))) if gram == tuple(nltk.word_tokenize(k))])\n",
    "        result.append(k.replace(' ','_'))\n",
    "    return \" \".join(sorted(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:18:22.573890Z",
     "start_time": "2019-07-27T06:18:22.565425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissertation\n",
      "<class 'str'>\n",
      "('Highland', 'Park')\n",
      "highland park\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dissertation highland_park'"
      ]
     },
     "execution_count": 1009,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = ['Dissertation', ('Highland','Park')]\n",
    "extract_keywords('Highland Park', keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:03:09.338137Z",
     "start_time": "2019-07-27T06:03:08.615457Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "(\"'tuple' object has no attribute 'lower'\", 'occurred at index 1868')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-968-6ecc697c4eb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlcbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords'\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mlcbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mextract_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'itemname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlcbo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlcbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlcbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6485\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6486\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-968-6ecc697c4eb8>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlcbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords'\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mlcbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mextract_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'itemname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlcbo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlcbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlcbo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-966-f3a271613fa9>\u001b[0m in \u001b[0;36mextract_keywords\u001b[0;34m(text, keywords)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgram\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgram\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: (\"'tuple' object has no attribute 'lower'\", 'occurred at index 1868')"
     ]
    }
   ],
   "source": [
    "lcbo['keywords']    = lcbo.apply(lambda row: extract_keywords(row['itemname'], keywords), axis='columns')\n",
    "lcbo = lcbo[lcbo['keywords'] !='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:18.993751Z",
     "start_time": "2019-07-27T06:02:17.538Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews['keywords'] = reviews.apply(lambda row: extract_keywords(row['whisky']), axis='columns')\n",
    "print(reviews.shape)\n",
    "reviews = reviews[reviews['keywords'] !='']\n",
    "print(reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:18.995543Z",
     "start_time": "2019-07-27T06:02:17.544Z"
    }
   },
   "outputs": [],
   "source": [
    "# in theory, any that show no keywords should not be carried by lcbo\n",
    "# to do a sanity check, let's check here for nonwords:\n",
    "nonwords = (reviews[reviews['keywords'] ==''][['whisky','keywords']]\n",
    "            .apply(lambda row: find_nonwords(row['whisky']), axis='columns')\n",
    "           )\n",
    "nonwords = list(nonwords.apply(pd.Series).stack().unique())\n",
    "# Filter out purly numeric values\n",
    "nonwords = [word for word in nonwords if not contains_digit(word)]\n",
    "\n",
    "# Filter out stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "nonwords = [word for word in nonwords if word not in stopWords]\n",
    "\n",
    "# Filter out punctuation\n",
    "nonwords = [word for word in nonwords if re.match('^[\\w]+$', word) is not None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:18.997186Z",
     "start_time": "2019-07-27T06:02:17.550Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_age(sentence):\n",
    "    # grab full words that are 1 or 2 digits only or end in yo, year, y\n",
    "    # but only if the word batch is not present\n",
    "    reg = '^(\\d\\d?)(?:yo|year|y|-year-old)?$'\n",
    "    batches = [word for word in nltk.word_tokenize(sentence) if word in ['batch']]\n",
    "    if len(batches) == 0:\n",
    "        return \" \".join(sorted([re.findall(reg,word, re.IGNORECASE)[0] for word in nltk.word_tokenize(sentence) if re.match(reg, word, re.IGNORECASE) is not None]))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a unique IDs to each whisky in the reviews table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:18.999129Z",
     "start_time": "2019-07-27T06:02:17.557Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = reviews.assign(RedditWhiskyID = reviews['whisky'].astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on lcbo based on keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.001019Z",
     "start_time": "2019-07-27T06:02:17.563Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = (reviews.reset_index()\n",
    "                  .set_index('keywords')\n",
    "                  .join(lcbo.set_index('keywords'), how='inner')\n",
    "                  .reset_index()\n",
    "                  .rename({'index':'keywords'}, axis='columns')\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.002751Z",
     "start_time": "2019-07-27T06:02:17.570Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.004699Z",
     "start_time": "2019-07-27T06:02:17.576Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate fuzzmatch using fuzztset which yields the best results\n",
    "reviews = reviews.rename({'whisky':'RedditWhiskyName','itemname':'Name'},axis='columns')\n",
    "reviews['fuzzratio']   = reviews.apply(lambda row: fuzz.ratio(row['RedditWhiskyName'],row['Name']), axis='columns')\n",
    "reviews['fuzzpartial'] = reviews.apply(lambda row: fuzz.partial_ratio(row['RedditWhiskyName'],row['Name']), axis='columns')\n",
    "reviews['fuzztsort']   = reviews.apply(lambda row: fuzz.token_sort_ratio(row['RedditWhiskyName'],row['Name']), axis='columns')\n",
    "reviews['fuzztset']    = reviews.apply(lambda row: fuzz.token_set_ratio(row['RedditWhiskyName'],row['Name']), axis='columns')\n",
    "reviews['fuzzmax']     = reviews.apply(lambda row: max(row['fuzzratio'],row['fuzzpartial'],row['fuzztsort'],row['fuzztset']), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.006292Z",
     "start_time": "2019-07-27T06:02:17.590Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews[(reviews['RedditWhiskyName'].str.contains(\"1792\")) & (reviews['RedditWhiskyName'].str.contains(\"Small\"))][['RedditWhiskyName','Name','fuzztset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.007905Z",
     "start_time": "2019-07-27T06:02:17.602Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add Rank column based on max fuzz\n",
    "fuzzfilter = reviews\n",
    "fuzzfilter[\"rank\"] = fuzzfilter.groupby(\"RedditWhiskyName\")[\"fuzztset\"].rank(\"dense\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.009630Z",
     "start_time": "2019-07-27T06:02:17.609Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add Age columns\n",
    "fuzzfilter['RedditAge'] = fuzzfilter.apply(lambda row: extract_age(row['RedditWhiskyName']), axis='columns')\n",
    "fuzzfilter['LcboAge']   = fuzzfilter.apply(lambda row: extract_age(row['Name'])            , axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.011481Z",
     "start_time": "2019-07-27T06:02:17.615Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out values where age does not match\n",
    "print(fuzzfilter.shape)\n",
    "fuzzfilter = fuzzfilter[fuzzfilter['RedditAge'] == fuzzfilter['LcboAge']]\n",
    "print(fuzzfilter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.013243Z",
     "start_time": "2019-07-27T06:02:17.627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test a threshold:\n",
    "fuzztest = fuzzfilter[(fuzzfilter['rank'] == 1) & (fuzzfilter['fuzztset'] >= 60)]\n",
    "print(fuzztest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.014886Z",
     "start_time": "2019-07-27T06:02:17.633Z"
    }
   },
   "outputs": [],
   "source": [
    "# save to csv to view results\n",
    "fuzztest[['RedditWhiskyName','Name','fuzzratio','fuzzpartial','fuzztsort','fuzztset','fuzzmax']].to_csv('fuzztest.csv')\n",
    "#fuzztest[['RedditWhiskyName','Name','fuzztset']].to_csv('fuzztest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.016420Z",
     "start_time": "2019-07-27T06:02:17.640Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(fuzztest.groupby('Name')['reviewID'].count()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.018024Z",
     "start_time": "2019-07-27T06:02:17.659Z"
    }
   },
   "outputs": [],
   "source": [
    "lcbomatches = pd.DataFrame(fuzztest.groupby('Name')['reviewID'].count())\n",
    "lcbomatches['matched'] = True\n",
    "lcbomatches = lcbomatches .drop('reviewID', axis='columns')\n",
    "\n",
    "lcbomatches = lcbo.set_index('itemname').join(lcbomatches)\n",
    "lcbomatches[lcbomatches['matched'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.019741Z",
     "start_time": "2019-07-27T06:02:17.665Z"
    }
   },
   "outputs": [],
   "source": [
    "extract_keywords('ABERFELDY 21 YEAR OLD HIGHLAND SINGLE MALT SCOTCH WHISKY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.021416Z",
     "start_time": "2019-07-27T06:02:17.670Z"
    }
   },
   "outputs": [],
   "source": [
    "rawreviews = pd.read_parquet('data/db_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.022964Z",
     "start_time": "2019-07-27T06:02:17.683Z"
    }
   },
   "outputs": [],
   "source": [
    "rawreviews[rawreviews['whisky'].str.contains('Aberfeldy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.024419Z",
     "start_time": "2019-07-27T06:02:17.689Z"
    }
   },
   "outputs": [],
   "source": [
    "extract_keywords('1922 HYDE RUM CASK FINISH IRISH WHISKEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.026005Z",
     "start_time": "2019-07-27T06:02:17.694Z"
    }
   },
   "outputs": [],
   "source": [
    "extract_keywords(\"Hyde 6 No. 4 President's Choice Rum Cask Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.027545Z",
     "start_time": "2019-07-27T06:02:17.701Z"
    }
   },
   "outputs": [],
   "source": [
    "lcbo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T06:02:19.029104Z",
     "start_time": "2019-07-27T06:02:17.707Z"
    }
   },
   "outputs": [],
   "source": [
    "331/663"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "378px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
