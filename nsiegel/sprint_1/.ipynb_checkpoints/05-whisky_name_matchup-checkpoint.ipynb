{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Libraries-and-Data\" data-toc-modified-id=\"Load-Libraries-and-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Libraries and Data</a></span></li><li><span><a href=\"#Initial-Grouping\" data-toc-modified-id=\"Initial-Grouping-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Initial Grouping</a></span></li><li><span><a href=\"#Extract-Keywords\" data-toc-modified-id=\"Extract-Keywords-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Extract Keywords</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-Keywords-from-Distillery-Names-(And-Other-Important-Terms)\" data-toc-modified-id=\"Find-Keywords-from-Distillery-Names-(And-Other-Important-Terms)-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Find Keywords from Distillery Names (And Other Important Terms)</a></span></li><li><span><a href=\"#Extract-Keywords\" data-toc-modified-id=\"Extract-Keywords-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Extract Keywords</a></span></li></ul></li><li><span><a href=\"#Extract-Age\" data-toc-modified-id=\"Extract-Age-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Extract Age</a></span></li><li><span><a href=\"#Join-Datasets\" data-toc-modified-id=\"Join-Datasets-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Join Datasets</a></span><ul class=\"toc-item\"><li><span><a href=\"#Join\" data-toc-modified-id=\"Join-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Join</a></span></li><li><span><a href=\"#Fuzzy-Match\" data-toc-modified-id=\"Fuzzy-Match-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Fuzzy Match</a></span></li><li><span><a href=\"#Add-Age\" data-toc-modified-id=\"Add-Age-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Add Age</a></span></li><li><span><a href=\"#Filter-NonMatching\" data-toc-modified-id=\"Filter-NonMatching-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Filter NonMatching</a></span></li></ul></li><li><span><a href=\"#Save-to-File\" data-toc-modified-id=\"Save-to-File-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Save to File</a></span><ul class=\"toc-item\"><li><span><a href=\"#Additional-Investigation\" data-toc-modified-id=\"Additional-Investigation-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Additional Investigation</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Purpose\n",
    "This notebook is to combine the reddit reviews with the LCBO product data.\n",
    "The difficulty in doing this comes from differing whisky names.\n",
    "To accomplish the join first we create a list of key phrases and extract them from the names. If whiskies have different key phrases, they do not match. Then we pull out the age of the whisky and compare that as well. Lastly, in terms of cases where there are still duplicates we use a fuzzy matching algorithm and take the highest rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:16.948153Z",
     "start_time": "2019-07-28T22:47:15.404555Z"
    }
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import sys\n",
    "import pdb\n",
    "from fuzzywuzzy import fuzz\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.596935Z",
     "start_time": "2019-07-28T22:47:16.952687Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/pyarrow/pandas_compat.py:708: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "/opt/tljh/user/lib/python3.6/site-packages/pyarrow/pandas_compat.py:735: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "reviews = pd.read_parquet('data/db_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.935485Z",
     "start_time": "2019-07-28T22:47:17.600162Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Passed non-file path: data/whisky_ids.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e7b9e36632f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwhiskyids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/whisky_ids.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_pandas_metadata'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         result = self.api.parquet.read_table(path, columns=columns,\n\u001b[0;32m--> 129\u001b[0;31m                                              **kwargs).to_pandas()\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, use_pandas_metadata, nthreads)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         return fs.read_parquet(source, columns=columns,\n\u001b[1;32m   1073\u001b[0m                                \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m                                use_pandas_metadata=use_pandas_metadata)\n\u001b[0m\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[0mpf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParquetFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pyarrow/filesystem.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(self, path, columns, metadata, schema, use_threads, nthreads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0muse_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_nthreads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         dataset = ParquetDataset(path, schema=schema, metadata=metadata,\n\u001b[0;32m--> 182\u001b[0;31m                                  filesystem=self)\n\u001b[0m\u001b[1;32m    183\u001b[0m         return dataset.read(columns=columns, use_threads=use_threads,\n\u001b[1;32m    184\u001b[0m                             use_pandas_metadata=use_pandas_metadata)\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, schema, metadata, split_row_groups, validate_schema, filters, metadata_nthreads)\u001b[0m\n\u001b[1;32m    858\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon_metadata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_manifest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             path_or_paths, self.fs, metadata_nthreads=metadata_nthreads)\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon_metadata_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m_make_manifest\u001b[0;34m(path_or_paths, fs, pathsep, metadata_nthreads)\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 raise IOError('Passed non-file path: {0}'\n\u001b[0;32m-> 1035\u001b[0;31m                               .format(path))\n\u001b[0m\u001b[1;32m   1036\u001b[0m             \u001b[0mpiece\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParquetDatasetPiece\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0mpieces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpiece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Passed non-file path: data/whisky_ids.parquet"
     ]
    }
   ],
   "source": [
    "whiskyids = pd.read_parquet('data/whisky_ids.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.941145Z",
     "start_time": "2019-07-28T22:47:15.476Z"
    }
   },
   "outputs": [],
   "source": [
    "lcbo = pd.read_parquet('data/lcbo_whisky.parquet').drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Grouping\n",
    "LCBO has some duplicate products due to having different bottle sizes or materials. We don't care about this so will group items by whisky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.943098Z",
     "start_time": "2019-07-28T22:47:15.485Z"
    }
   },
   "outputs": [],
   "source": [
    "# we actually don't care if a product is in a plastic bottle or not for review purposes, so let's rename them:\n",
    "lcbo['itemname'] = lcbo['itemname'].str.replace('\\(PET\\)','', case=False,regex=True).str.strip()\n",
    "\n",
    "# add count to see how many of the same whisky name we have\n",
    "lcbo['count'] = lcbo.groupby('itemname')['itemnumber'].transform('count')\n",
    "\n",
    "# add a metric to see how far from 750 a bottle is (we want to drop duplicate products of different sizes)\n",
    "lcbo = lcbo.assign(sizedelta = abs(lcbo['productsize'] - 750))\n",
    "\n",
    "# keep only the entry closest to 750 and in case of tie the one with higher price (assuming its the nonpet) :\n",
    "lcbo['rank'] = lcbo.groupby(\"itemname\")['sizedelta'].rank(\"first\", ascending=True)\n",
    "lcbo = lcbo[(lcbo['rank'] == 1)]\n",
    "\n",
    "# drop the added columns since we don't need them anymore\n",
    "lcbo = lcbo.drop(['count','sizedelta','rank'], axis='columns')\n",
    "\n",
    "# while we are here we need to fix the name of a specific whisky:\n",
    "lcbo.loc[lcbo.itemname.str.contains('GLENFARCLAS12'),'itemname'] = \"GLENFARCLAS 12-YEAR-OLD HIGHLAND SINGLE MALT SCOTCH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Keywords from Distillery Names (And Other Important Terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.944788Z",
     "start_time": "2019-07-28T22:47:15.493Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_nonwords(sentence):\n",
    "    #return nltk.word_tokenize(sentence)\n",
    "    return [str.lower(word) for word in nltk.word_tokenize(sentence) if not is_word(word)]\n",
    "    \n",
    "def is_word(word):\n",
    "    if wordnet.synsets(word):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def contains_digit(word):\n",
    "    return any(char.isdigit() for char in word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.946741Z",
     "start_time": "2019-07-28T22:47:15.502Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find all words in whisky names that are not english words\n",
    "keywords = lcbo.apply(lambda row: find_nonwords(row['itemname']), axis='columns')\n",
    "\n",
    "# Turn into one list without duplicates\n",
    "keywords = list(keywords.apply(pd.Series).stack().unique())\n",
    "\n",
    "# Filter out purly numeric values\n",
    "keywords = [word for word in keywords if not contains_digit(word)]\n",
    "\n",
    "# Filter out stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "keywords = [word for word in keywords if word not in stopWords]\n",
    "\n",
    "# Filter out punctuation\n",
    "keywords = [word for word in keywords if re.match('^[\\w]+$', word) is not None]\n",
    "\n",
    "# Filter out words that aren't applicable:\n",
    "# These are either: generic descriptors or whisky regions\n",
    "filterlist = ['peated', 'campbeltown', 'speyside', 'yo', 'st', 'oaked', 'wheated', 'ol', 'bbq', 'exper']\n",
    "\n",
    "keywords = [word for word in keywords if word not in filterlist]\n",
    "\n",
    "newwords = [\n",
    "            # brands\n",
    "            '101','1792', 'gibsons', 'signature', 'ballantines',\n",
    "            'makers', 'bakers','blantons','mcclelland','bookers','patricks','gentleman','jack',\n",
    "            'prichards','stranahans','dewars',\n",
    "            'jeffersons','liquormens', \n",
    "            'barrelling','cattos','blantons','founders',\n",
    "            'walkers','teachers','bells','royal','grants','o.f.c.', 'century',\n",
    "            # bigrams need to both be matched:\n",
    "            ('jack','daniels'), ('knob','creek'),('crown','royal'),('canadian','club'),\n",
    "            ('highland','park'), ('forty','creek'),('proof', 'whisky'), ('canadian','rockies'),\n",
    "            'owl', 'jefferson', 'teacher',\n",
    "            'sazerac', 'caribou', 'wiser', 'walker', 'grouse', 'alberta', 'grant', 'bell', \n",
    "            'dewar',  'rittenhouse', 'revel', 'roses', \n",
    "            'writers', 'writer', 'rogue',  'colonel', 'weller', 'booker', 'mist', 'challenge',\n",
    "            'redbreast','jts', 'casg','burns', '601',\n",
    "            # qualities\n",
    "            'organic','vintage','quiet', 'classic', 'select', #'proof', 'rare', \n",
    "            # region (careful with these)\n",
    "             'canada', #'islay', 'canadian',\n",
    "            # locations\n",
    "            'virginia','dublin','shetland','trafalgar','caribbean','windsor',  'halifax',\n",
    "            # names\n",
    "            'patrick', 'gretzky', 'cody', 'charlotte','tucker','prescott',\n",
    "            # animals\n",
    "            'bull', 'dog', 'turkey', 'monkey', 'beast', 'fox', 'buffalo','crow','horse', \n",
    "            # colors\n",
    "            'red', 'blue', 'yellow', 'green', 'black', 'brown', 'white', 'gold', 'silver', #'copper',\n",
    "            'golden','blacker', 'golder', 'redder', 'darker',\n",
    "            'dark',\n",
    "            # type\n",
    "            'rye',\n",
    "            # barrels\n",
    "            'cognac', 'sherry', 'amarone', 'champagne', #'stout', messes up caskmates\n",
    "            'brandy', 'madeira', 'bordeaux', 'sauternes', 'burgundy',\n",
    "            'sassicaia', 'tokaji', 'rum', 'sherry'\n",
    "            # barrel count\n",
    "            'triple', 'double', #'single',\n",
    "            # woods\n",
    "            'cedar', 'heartwood', 'springwood', 'virgin', 'redwood', 'wood', 'cork', 'cask', 'new',\n",
    "            # game of thrones\n",
    "            'stark', 'tully',\n",
    "            # flavours\n",
    "            'apple', 'vanilla', 'peach', 'honey', 'maple', 'spiced', 'toasted', 'seasoned',\n",
    "            # other\n",
    "            #'small',\n",
    "            'irishman', 'rebel', 'compass',   \n",
    "            'stalk', 'centennial', 'forester', 'powers', 'temple', \n",
    "            'antiquity', 'feathery', 'few',  'burnside',   'larceny', 'tango', 'king',\n",
    "            'moray', 'twelve', 'reunion',   'maestri', #'reserve', \n",
    "            'sexton', 'ezra', 'bastille',  'orphan', 'founder',  'wedding', 'shoe',\n",
    "            'caramel', 'moonshine', 'cooper',  'benchmark',\n",
    "            'smws','valinch', 'hermitage','home',    'traditional', 'bush', 'art','diamond', \n",
    "            'alpha', 'dawn', 'dusk', 'surf', 'elements', 'growth', 'bere', \n",
    "            'cuvee', 'infinity', 'octomore', 'resurrection',\n",
    "            'waves', 'river', 'silk' ,'signal', 'winter', 'snow', 'ice', 'fire', \n",
    "            'harvest', 'blenders', 'chairman','ellington', 'kirkland',\n",
    "            'mcadam', 'glacier', 'skate', 'pike', 'ileach',\n",
    "            'macaloney', 'cured', 'grain',  'sour', 'tornado',\n",
    "            'hedonism', 'evolution', 'cross', 'glasgow','indian',\n",
    "            'heritage',  'devil', 'brooks', 'alba', 'major', 'naked', 'eades', 'light',  'entrapment',  'oyo',\n",
    "            'palm', 'lochnagar', 'willett', 'north', 'dissertation', 'last', 'legacy'\n",
    "           ]\n",
    "keywords = keywords + newwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.949068Z",
     "start_time": "2019-07-28T22:47:15.509Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract keywords from text\n",
    "def extract_keywords(text, keywords):\n",
    "    from nltk import ngrams\n",
    "    text = text.lower().replace(\"mcclelland's\",\"mcclelland\")\n",
    "    text = text.lower().replace(\"hayden's\",\"hayden\")\n",
    "    text = text.lower().replace(\"'s\",\"s\")\n",
    "    result = []\n",
    "    for k in keywords:\n",
    "        if type(k) == tuple:\n",
    "            # lower each word in the tuple and turn into a string\n",
    "            (word1, word2) = k\n",
    "            k = \" \".join([word1.lower(),word2.lower()])\n",
    "        else:\n",
    "            # lower the word\n",
    "            k = k.lower()\n",
    "        count = len([gram for gram in ngrams(nltk.word_tokenize(text),len(nltk.word_tokenize(k))) if gram == tuple(nltk.word_tokenize(k))])\n",
    "        if count > 0:\n",
    "            result.append(k.replace(' ','_'))\n",
    "    return \" \".join(sorted(result))\n",
    "\n",
    "# Function to multiprocess an entire dataframe\n",
    "def extract_keywords_dataframe(df, columnname, keywords):\n",
    "    # create dataframe to hold results\n",
    "    global results\n",
    "    results = pd.DataFrame(columns=[columnname,'keywords'])\n",
    "    \n",
    "    # select only the column we want and make unique to save some time\n",
    "    dfnames = df[columnname].unique()\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "    \n",
    "    # call function for each name\n",
    "    for name in dfnames:\n",
    "        pool.apply_async(extract_keywords_row, args=(columnname, name, keywords), callback=collect_result)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # join back on original dataframe\n",
    "    return (df.set_index(columnname)\n",
    "              .join(results.set_index(columnname))\n",
    "              .reset_index()\n",
    "              .rename({'index':columnname}, axis='columns')\n",
    "           )\n",
    "    \n",
    "# Function to be ran in multiprocess on each item\n",
    "def extract_keywords_row(columnname, text, keywords):\n",
    "    newitem = {}\n",
    "    newitem[columnname] = text\n",
    "    newitem['keywords'] = extract_keywords(text, keywords)\n",
    "    return newitem\n",
    "    \n",
    "# Function to collect results from multiprocess\n",
    "def collect_result(result):\n",
    "    global results\n",
    "    results = results.append(result,ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add keywords to LCBO data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.950729Z",
     "start_time": "2019-07-28T22:47:15.517Z"
    }
   },
   "outputs": [],
   "source": [
    "results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.952460Z",
     "start_time": "2019-07-28T22:47:15.523Z"
    }
   },
   "outputs": [],
   "source": [
    "lcbo = extract_keywords_dataframe(lcbo, 'itemname', keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to review data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.953998Z",
     "start_time": "2019-07-28T22:47:15.532Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews = reviews.reset_index().rename({'index':'reviewID'}, axis='columns')\n",
    "reviews = extract_keywords_dataframe(reviews, 'whisky', keywords)\n",
    "print(reviews.shape)\n",
    "reviews = reviews[reviews['keywords'] !='']\n",
    "print(reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.955599Z",
     "start_time": "2019-07-28T22:47:15.539Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews.to_parquet('db_reviews_keywords.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.957096Z",
     "start_time": "2019-07-28T22:47:15.547Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_parquet('db_reviews_keywords.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.958867Z",
     "start_time": "2019-07-28T22:47:15.555Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_age(sentence):\n",
    "    # remove # words to not confuse age\n",
    "    sentence = re.sub(\"\\#\\d*\",'', sentence)\n",
    "    # grab full words that are 1 or 2 digits only or end in yo, year, y\n",
    "    # but only if the word batch is not present\n",
    "    reg = '^(\\d\\d?)(?:yo|year|y|-year-old)?$'\n",
    "    batches = [word for word in nltk.word_tokenize(sentence) if word in ['batch']]\n",
    "    if len(batches) == 0:\n",
    "        return \" \".join(sorted([re.findall(reg,word, re.IGNORECASE)[0] for word in nltk.word_tokenize(sentence) if re.match(reg, word, re.IGNORECASE) is not None]))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T18:07:32.153434Z",
     "start_time": "2019-07-28T18:07:32.150287Z"
    }
   },
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a unique IDs to each whisky in the reviews table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.960402Z",
     "start_time": "2019-07-28T22:47:15.565Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = reviews.assign(RedditWhiskyID = reviews['whisky'].astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on lcbo based on keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.962075Z",
     "start_time": "2019-07-28T22:47:15.573Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = (reviews.set_index('keywords')\n",
    "                  .join(lcbo.set_index('keywords'), how='inner')\n",
    "                  .reset_index()\n",
    "                  .rename({'index':'keywords'}, axis='columns')\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.963582Z",
     "start_time": "2019-07-28T22:47:15.581Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.965117Z",
     "start_time": "2019-07-28T22:47:15.589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate fuzzmatch using fuzztset which yields the best results\n",
    "reviews = reviews.rename({'whisky':'RedditWhiskyName','itemname':'Name'},axis='columns')\n",
    "reviews['fuzztset']    = reviews.apply(lambda row: fuzz.token_set_ratio(row['RedditWhiskyName'],row['Name']), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.967049Z",
     "start_time": "2019-07-28T22:47:15.595Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add Rank column based on max fuzz\n",
    "fuzzfilter = reviews\n",
    "fuzzfilter[\"rank\"] = fuzzfilter.groupby(\"RedditWhiskyName\")[\"fuzztset\"].rank(\"dense\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.968678Z",
     "start_time": "2019-07-28T22:47:15.605Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add Age columns\n",
    "fuzzfilter['RedditAge'] = fuzzfilter.apply(lambda row: extract_age(row['RedditWhiskyName']), axis='columns')\n",
    "fuzzfilter['LcboAge']   = fuzzfilter.apply(lambda row: extract_age(row['Name'])            , axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter NonMatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.970241Z",
     "start_time": "2019-07-28T22:47:15.613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out values where age does not match\n",
    "print(fuzzfilter.shape)\n",
    "fuzzfilter = fuzzfilter[fuzzfilter['RedditAge'] == fuzzfilter['LcboAge']]\n",
    "print(fuzzfilter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.972083Z",
     "start_time": "2019-07-28T22:47:15.620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's set threshold at 59 %. This is based on some trial and error.\n",
    "matches = fuzzfilter[(fuzzfilter['rank'] == 1) & (fuzzfilter['fuzztset'] >= 59)]\n",
    "print(matches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.974225Z",
     "start_time": "2019-07-28T22:47:15.626Z"
    }
   },
   "outputs": [],
   "source": [
    "# save to csv to view results\n",
    "matches[['RedditWhiskyName','Name','fuzztset']].to_csv('fuzztest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many we've matched up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.975876Z",
     "start_time": "2019-07-28T22:47:15.635Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(matches.groupby('Name')['reviewID'].count()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.977534Z",
     "start_time": "2019-07-28T22:47:15.643Z"
    }
   },
   "outputs": [],
   "source": [
    "lcbo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.979328Z",
     "start_time": "2019-07-28T22:47:15.657Z"
    }
   },
   "outputs": [],
   "source": [
    "100*415/573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "72 % matched is pretty good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.980841Z",
     "start_time": "2019-07-28T22:47:15.669Z"
    }
   },
   "outputs": [],
   "source": [
    "matches['itemnumber'] = matches['itemnumber'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.982699Z",
     "start_time": "2019-07-28T22:47:15.676Z"
    }
   },
   "outputs": [],
   "source": [
    "matches.to_parquet('data/matches.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at ones that were not matched and figure out why:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.984313Z",
     "start_time": "2019-07-28T22:47:15.710Z"
    }
   },
   "outputs": [],
   "source": [
    "lcbomatches = pd.DataFrame(matches.groupby('Name')['reviewID'].count())\n",
    "lcbomatches['matched'] = True\n",
    "lcbomatches = lcbomatches .drop('reviewID', axis='columns')\n",
    "\n",
    "lcbomatches = lcbo.set_index('itemname').join(lcbomatches)\n",
    "lcbomatches[lcbomatches['matched'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.986293Z",
     "start_time": "2019-07-28T22:47:15.724Z"
    }
   },
   "outputs": [],
   "source": [
    "#ones that seem to actually not exist in reddit reviews:\n",
    "SIGNATURE RARE WHISKEY\n",
    "CANADIAN CLUB CLASSIC 12 YEAR OLD\t\n",
    "TOMINTOUL 10 YEAR OLD SPEYSIDE GLENLIVET SINGLE MALT SCOTCH WHISKY\n",
    "CARIBOU CROSSING SINGLE BARREL CANADIAN WHISKY\n",
    "DEWARS SIGNATURE BLENDED SCOTCH WHISKY\n",
    "SPICEBOX CANADIAN SPICED WHISKY\n",
    "CANADA GOLD WHISKY\n",
    "ST. PATRICK'S IRISH WHISKEY 7 YO\n",
    "BLACK DOG TRIPLE GOLD RESERVE\n",
    "TYRCONNELL MADEIRA CASK SINGLE MALT IRISH WHISKEY\n",
    "SIGNAL HILL CANADIAN WHISKY\n",
    "TOKINOKA BLACK BLENDED WHISKY\n",
    "GLEN ELGIN 18-YEAR-OLD SCOTCH WHISKY\n",
    "CARAMEL MOONSHINE\n",
    "SEAGRAMS 83 WHISKY\n",
    "COOPER'S REVIVAL RYE WHISKY\n",
    "ANCNOC PEATHEART SINGLE MALT WHISKY\n",
    "TIMOROUS BEASTIE HIGHLAND MALT 10 YO\n",
    "JURA SEVEN WOOD\n",
    "TOKINOKA WHITE JAPANESE WHISKY\n",
    "JACK DANIEL'S LEGACY # 1\n",
    "CROWN ROYAL PEACH\n",
    "ALUMNI WHISKY SERIES - PAUL COFFEY\n",
    "ALUMNI WHISKY SERIES - LARRY ROBINSON\n",
    "ALUMNI WHISKY SERIES - DARRYL SITTLER\n",
    "ROYAL CHALLENGE SPIRIT WHISKY\n",
    "ROZELIEURES ORIGINE COLLECTION SINGLE MALT WHISKY\n",
    "NIAGARA FALLS RYE CANADIAN WHISKY\n",
    "\n",
    "# ones that are mismatched\n",
    "DARKER SIDE\n",
    "BLACK ART 6.1\n",
    "BENCHMARK OLD NO. 8 BRAND KENTUCKY STRAIGHT BOURBON\n",
    "LEGENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.988263Z",
     "start_time": "2019-07-28T22:47:15.734Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = \"GLENFIDDICH EXPER SERIES #4 FIRE & CANE\"\n",
    "redditname = \"Glenfiddich Experimental Series Fire & Cane\"\n",
    "print(extract_keywords(name, keywords))\n",
    "print(extract_keywords(redditname, keywords))\n",
    "print(fuzz.token_set_ratio(name,redditname))\n",
    "print(extract_age(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.989876Z",
     "start_time": "2019-07-28T22:47:15.749Z"
    }
   },
   "outputs": [],
   "source": [
    "re.sub(\"\\#\\d*\",'', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.992063Z",
     "start_time": "2019-07-28T22:47:15.756Z"
    }
   },
   "outputs": [],
   "source": [
    "fuzz.token_set_ratio(name,redditname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.993722Z",
     "start_time": "2019-07-28T22:47:15.764Z"
    }
   },
   "outputs": [],
   "source": [
    "rawreviews = pd.read_parquet('data/db_reviews.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T22:47:17.995579Z",
     "start_time": "2019-07-28T22:47:15.776Z"
    }
   },
   "outputs": [],
   "source": [
    "rawreviews[rawreviews['whisky'].str.contains('Greyjoy')]\n",
    "#rawreviews[rawreviews['whisky'].str.contains('Dalmore') & rawreviews['whisky'].str.contains('Wood')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "378px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
